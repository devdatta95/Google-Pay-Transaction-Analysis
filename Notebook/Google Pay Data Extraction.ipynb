{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c73a20-917b-42de-9ccc-e0798d018dd2",
   "metadata": {},
   "source": [
    "# Extract HTML Data Into CSV FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af81bbaf-de35-4226-9f5d-a316609a0ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# File paths\n",
    "INPUT_FILE = Path(\"My Activity.html\")\n",
    "CATEGORY_CSV = Path(\"category_list.csv\")\n",
    "\n",
    "# Logging config\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "LOG_LEVEL = \"INFO\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c4d4e15-a291-43f5-8ee9-a2faca8b0f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-05 23:38:39,912 - INFO - Starting extraction from file: Shruti.html\n",
      "2025-09-05 23:38:39,920 - INFO - Loaded category CSV with encoding: utf-8\n",
      "2025-09-05 23:38:39,922 - INFO - Loaded 20 categories from category_list.csv\n",
      "2025-09-05 23:38:40,164 - INFO - Parsing transactions from text lines...\n",
      "2025-09-05 23:38:40,966 - INFO - Parsed 3497 transactions\n",
      "2025-09-05 23:38:41,058 - INFO - Saved extracted data to extracted_gpay_data.csv\n",
      "2025-09-05 23:38:41,062 - INFO - Extraction complete. Rows: 3497, Cols: 20\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Google Pay HTML transaction extractor.\n",
    "\n",
    "This script parses Google Pay HTML export, extracts structured transactions,\n",
    "and writes them into a clean CSV. It supports categorization based on a\n",
    "predefined category CSV.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import csv\n",
    "import logging\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import html as pyhtml\n",
    "import pandas as pd\n",
    "# from config import INPUT_FILE, CATEGORY_CSV, OUTPUT_SUFFIX, LOG_FORMAT, LOG_LEVEL\n",
    "\n",
    "try:\n",
    "    from dateutil import parser as dateparser\n",
    "except Exception:\n",
    "    dateparser = None\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=LOG_LEVEL, format=LOG_FORMAT)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_category_map(path: Path) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Load category keywords from CSV and build a mapping.\n",
    "    Tries UTF-8 first, falls back to cp1252/latin1.\n",
    "    \"\"\"\n",
    "    encodings_to_try = [\"utf-8\", \"cp1252\", \"latin1\"]\n",
    "    df = None\n",
    "\n",
    "    for enc in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(path, dtype=str, encoding=enc).fillna(\"\")\n",
    "            logger.info(\"Loaded category CSV with encoding: %s\", enc)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Failed to load CSV with encoding %s: %s\", enc, e)\n",
    "\n",
    "    if df is None:\n",
    "        logger.error(\"Could not load category CSV at all.\")\n",
    "        return {}\n",
    "\n",
    "    category_map: Dict[str, List[str]] = {}\n",
    "    for col in df.columns:\n",
    "        kws = [str(x).strip().lower() for x in df[col].tolist() if str(x).strip()]\n",
    "        seen, out = set(), []\n",
    "        for kw in kws:\n",
    "            if kw not in seen:\n",
    "                seen.add(kw)\n",
    "                out.append(kw)\n",
    "        if out:\n",
    "            category_map[col] = out\n",
    "    logger.info(\"Loaded %d categories from %s\", len(category_map), path)\n",
    "    return category_map\n",
    "\n",
    "\n",
    "\n",
    "def html_to_text_fast(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert raw HTML into plain text by stripping tags and decoding entities.\n",
    "    \"\"\"\n",
    "    html = re.sub(r\"(?is)<(script|style).*?>.*?</\\1>\", \" \", html)\n",
    "    html = re.sub(r\"(?is)<br\\s*/?>\", \"\\n\", html)\n",
    "    html = re.sub(r\"(?is)<[^>]+>\", \"\\n\", html)\n",
    "    text = pyhtml.unescape(html)\n",
    "    text = text.replace(\"\\u00A0\", \" \").replace(\"\\u202F\", \" \")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    \"\"\"Normalize whitespace and trim string.\"\"\"\n",
    "    s = s.replace(\"\\u00A0\", \" \").replace(\"\\u202F\", \" \")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def extract_amount(sentence: str) -> Optional[float]:\n",
    "    \"\"\"Extract INR amount from a sentence like 'Paid ₹ 200.50'.\"\"\"\n",
    "    m = re.search(r\"₹\\s*([0-9][0-9,]*(?:\\.\\d{1,2})?)\", sentence)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1).replace(\",\", \"\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_type_party_instrument(sentence: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n",
    "    \"\"\"Extract transaction type, counterparty, and instrument from a sentence.\"\"\"\n",
    "    ttype, party, instr = None, None, None\n",
    "\n",
    "    try:\n",
    "        mt = re.match(r\"^(Paid|Sent|Received)\\b\", sentence, flags=re.I)\n",
    "        if mt:\n",
    "            ttype = mt.group(1).title()\n",
    "\n",
    "        mp = re.search(r\"\\b(?:to|from|at)\\s+(.+?)(?:\\s+using\\b|$)\", sentence, flags=re.I)\n",
    "        if mp:\n",
    "            party = mp.group(1).strip(\" .;\")\n",
    "\n",
    "        mi = re.search(r\"\\busing\\s+(.+)$\", sentence, flags=re.I)\n",
    "        if mi:\n",
    "            instr = mi.group(1).strip(\" .;\")\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to extract type/party/instrument: %s\", e)\n",
    "\n",
    "    return ttype, party, instr\n",
    "\n",
    "\n",
    "def extract_last4(instr: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Extract last 4 digits from a masked instrument string.\"\"\"\n",
    "    if not instr:\n",
    "        return None\n",
    "    try:\n",
    "        m = re.search(r\"(?:X|\\*)+(?:\\d{2,})\", instr, flags=re.I)\n",
    "        if m:\n",
    "            digits = re.findall(r\"\\d\", m.group(0))\n",
    "            if len(digits) >= 4:\n",
    "                return \"\".join(digits[-4:])\n",
    "        m2 = re.search(r\"(\\d{4,})\\b\", instr)\n",
    "        if m2:\n",
    "            return m2.group(1)[-4:]\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_ts(line: Optional[str]):\n",
    "    \"\"\"Parse timestamp into multiple formats (ISO, date, time, weekday, month).\"\"\"\n",
    "    if not line or not dateparser:\n",
    "        return None, None, None, None, None, None\n",
    "    try:\n",
    "        dt = dateparser.parse(line)\n",
    "        return (\n",
    "            dt.isoformat(),\n",
    "            dt.date().isoformat(),\n",
    "            dt.strftime(\"%I:%M:%S %p\"),\n",
    "            dt.strftime(\"%H:%M:%S\"),\n",
    "            dt.strftime(\"%A\"),\n",
    "            dt.strftime(\"%Y-%m\"),\n",
    "        )\n",
    "    except Exception:\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "\n",
    "def match_category(counterparty: Optional[str], category_map: Dict[str, List[str]]) -> Optional[str]:\n",
    "    \"\"\"Match counterparty name against category keywords.\"\"\"\n",
    "    if not isinstance(counterparty, str) or not counterparty.strip():\n",
    "        return None\n",
    "    name = counterparty.lower().strip()\n",
    "    for cat, kws in category_map.items():\n",
    "        for kw in kws:\n",
    "            if kw and kw in name:\n",
    "                return cat\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_text_lines(lines: List[str], source_name: str, category_map: Dict[str, List[str]]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Parse lines of text and extract structured transactions.\n",
    "\n",
    "    Args:\n",
    "        lines: List of normalized text lines.\n",
    "        source_name: Original file name.\n",
    "        category_map: Category keywords.\n",
    "\n",
    "    Returns:\n",
    "        List of transaction dicts.\n",
    "    \"\"\"\n",
    "    logger.info(\"Parsing transactions from text lines...\")\n",
    "    txns = []\n",
    "    start_re = re.compile(r\"^(Paid|Sent|Received)\\s+₹\\s*([0-9][0-9,]*(?:\\.\\d{1,2})?)\", re.I)\n",
    "    month_word = r\"(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\"\n",
    "    ts_re = re.compile(rf\"\\b{month_word}\\s+\\d{{1,2}},\\s+\\d{{4}},\\s+\\d{{1,2}}:\\d{{2}}:\\d{{2}}\\s+(?:AM|PM)\\s+GMT[+\\-]\\d{{2}}:\\d{{2}}\\b\")\n",
    "\n",
    "    n, i = len(lines), 0\n",
    "    while i < n:\n",
    "        line = lines[i]\n",
    "        if not start_re.search(line):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sentence = line\n",
    "            ttype, party, instr = extract_type_party_instrument(sentence)\n",
    "            amount = extract_amount(sentence)\n",
    "            last4 = extract_last4(instr)\n",
    "\n",
    "            # Timestamp\n",
    "            ts_line, next_start_at = None, None\n",
    "            for j in range(i + 1, min(n, i + 25)):\n",
    "                if not ts_line:\n",
    "                    m = ts_re.search(lines[j])\n",
    "                    if m:\n",
    "                        ts_line = m.group(0)\n",
    "                if next_start_at is None and start_re.search(lines[j]):\n",
    "                    next_start_at = j\n",
    "                if ts_line and next_start_at:\n",
    "                    break\n",
    "            dt_iso, date_s, time_12, time_24, weekday, month = parse_ts(ts_line)\n",
    "\n",
    "            # Status and Details ID\n",
    "            details_id, status = None, None\n",
    "            end_idx = next_start_at if next_start_at else min(n, i + 25)\n",
    "            for j in range(i + 1, end_idx):\n",
    "                s, low = lines[j], lines[j].lower()\n",
    "                if not status and low in {\n",
    "                    \"completed\",\"failed\",\"pending\",\"cancelled\",\"canceled\",\"processing\",\"refunded\",\"success\",\"succeeded\"\n",
    "                }:\n",
    "                    status = s.title()\n",
    "                if \"details\" in low and \":\" in s:\n",
    "                    for k in range(j + 1, min(end_idx, j + 5)):\n",
    "                        x = lines[k].strip()\n",
    "                        if x and not x.endswith(\":\") and re.match(r\"^[A-Za-z0-9+/=_-]{6,}$\", x):\n",
    "                            details_id = x\n",
    "                            break\n",
    "                if not details_id and s and not s.endswith(\":\") and re.match(r\"^[A-Za-z0-9+/=_-]{10,}$\", s):\n",
    "                    details_id = s\n",
    "\n",
    "            direction = \"outgoing\" if (ttype in {\"Paid\", \"Sent\"}) else (\"incoming\" if ttype == \"Received\" else None)\n",
    "            category_guess = match_category(party, category_map)\n",
    "            if not status:\n",
    "                status = \"No Status Found\" if ttype == \"Paid\" else None\n",
    "\n",
    "            txns.append({\n",
    "                \"source_file\": source_name,\n",
    "                \"transaction_type\": ttype,\n",
    "                \"direction\": direction,\n",
    "                \"status\": status,\n",
    "                \"amount_inr\": amount,\n",
    "                \"currency\": \"INR\" if amount is not None else None,\n",
    "                \"counterparty\": party,\n",
    "                \"category_guess\": category_guess,\n",
    "                \"payment_instrument\": instr,\n",
    "                \"account_last4\": last4,\n",
    "                \"datetime_local\": dt_iso,\n",
    "                \"date\": date_s,\n",
    "                \"time\": time_12,\n",
    "                \"time_24h\": time_24,\n",
    "                \"weekday\": weekday,\n",
    "                \"month\": month,\n",
    "                \"year\": date_s.split(\"-\")[0] if date_s else None,\n",
    "                \"product\": \"Google Pay\",\n",
    "                \"details_id\": details_id,\n",
    "                \"raw_text\": sentence,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.error(\"Failed parsing transaction at line %d: %s\", i, e)\n",
    "\n",
    "        i = next_start_at if next_start_at else (i + 1)\n",
    "\n",
    "    logger.info(\"Parsed %d transactions\", len(txns))\n",
    "    return txns\n",
    "\n",
    "\n",
    "def extract_single_file(input_file: Path, category_csv: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract transactions from a single Google Pay HTML file.\n",
    "\n",
    "    Args:\n",
    "        input_file: Path to HTML file.\n",
    "        category_csv: Path to category CSV.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with extracted transactions.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting extraction from file: %s\", input_file)\n",
    "\n",
    "    # Load categories\n",
    "    cat_map = load_category_map(category_csv)\n",
    "\n",
    "    try:\n",
    "        raw = input_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception as e:\n",
    "        logger.critical(\"Failed to read input file: %s\", e)\n",
    "        raise\n",
    "\n",
    "    text = html_to_text_fast(raw)\n",
    "    lines = [normalize(ln) for ln in text.splitlines() if normalize(ln)]\n",
    "    rows = parse_text_lines(lines, source_name=input_file.name, category_map=cat_map)\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Ensure all columns exist\n",
    "    cols = [\n",
    "        \"source_file\",\"transaction_type\",\"direction\",\"status\",\"amount_inr\",\"currency\",\n",
    "        \"counterparty\",\"category_guess\",\"payment_instrument\",\"account_last4\",\n",
    "        \"datetime_local\",\"date\",\"time\",\"time_24h\",\"weekday\",\"month\",\"year\",\n",
    "        \"product\",\"details_id\",\"raw_text\"\n",
    "    ]\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = None\n",
    "    df = df[cols]\n",
    "\n",
    "    # Deduplicate\n",
    "    def make_key(row):\n",
    "        did = row.get(\"details_id\")\n",
    "        if pd.notna(did) and str(did).strip():\n",
    "            return (\"id\", str(did).strip())\n",
    "        return (\n",
    "            \"composite\",\n",
    "            row.get(\"transaction_type\"),\n",
    "            row.get(\"amount_inr\"),\n",
    "            row.get(\"currency\"),\n",
    "            (row.get(\"counterparty\") or \"\").strip().lower(),\n",
    "            (row.get(\"payment_instrument\") or \"\").strip().lower(),\n",
    "            row.get(\"account_last4\"),\n",
    "            row.get(\"datetime_local\"),\n",
    "        )\n",
    "    keys = df.apply(make_key, axis=1)\n",
    "    df = df.loc[~keys.duplicated()].reset_index(drop=True)\n",
    "\n",
    "    # 🔹 Always write a common file name\n",
    "    out_path = input_file.parent / \"extracted_gpay_data.csv\"\n",
    "    try:\n",
    "        df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "        logger.info(\"Saved extracted data to %s\", out_path)\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to write output file: %s\", e)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = extract_single_file(INPUT_FILE, CATEGORY_CSV)\n",
    "    logger.info(\"Extraction complete. Rows: %d, Cols: %d\", df.shape[0], df.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5c068-1175-4777-8bab-780e56af73cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
